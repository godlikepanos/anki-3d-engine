// Copyright (C) 2009-present, Panagiotis Christopoulos Charitos and contributors.
// All rights reserved.
// Code licensed under the BSD License.
// http://www.anki3d.org/LICENSE

#pragma anki 16bit

#pragma anki mutator SSR_SAMPLE_GBUFFER 0 1
#pragma anki mutator INDIRECT_DIFFUSE_CLIPMAPS 0 1

#pragma anki technique Classification comp mutators
#pragma anki technique Ssr comp
#pragma anki technique ReflectionProbeFallback comp mutators
#pragma anki technique RtMaterialFetch rgen mutators INDIRECT_DIFFUSE_CLIPMAPS
#pragma anki technique SpatialDenoise comp mutators
#pragma anki technique TemporalDenoise comp mutators
#pragma anki technique BilateralDenoiseVertical comp mutators
#pragma anki technique BilateralDenoiseHorizontal comp mutators

#include <AnKi/Shaders/RtMaterialFetch.hlsl>
#include <AnKi/Shaders/Include/GpuSceneTypes.h>
#include <AnKi/Shaders/PackFunctions.hlsl>
#include <AnKi/Shaders/LightFunctions.hlsl>
#include <AnKi/Shaders/ImportanceSampling.hlsl>
#include <AnKi/Shaders/BilateralFilter.hlsl>
#include <AnKi/Shaders/SsRaymarching.hlsl>
#include <AnKi/Shaders/ClusteredShadingFunctions.hlsl>
#include <AnKi/Shaders/IndirectDiffuseClipmaps.hlsl>
#include <AnKi/Shaders/TemporalAA.hlsl>

// Config & debug
constexpr F32 kSpatialUpscalingPcfTexelOffset = 8.0;
#define SPATIAL_UPSCALING_POISON_KERNEL kPoissonDisk8
constexpr F32 kMaxBilateralSamples = 5.0;
constexpr F32 kGaussianSigma = 0.55;
constexpr Bool kStochasticReflections = true;
constexpr Bool kTryShadowmapFirst = true;
constexpr Bool kDisableDenoising = false;
constexpr F32 kTMinBias = -1.0;
constexpr Bool kExtraSsrRejection = true;
constexpr Bool kDebugSsr = false;
constexpr Bool kSsrHallucinate = true;
constexpr Bool kSsrHallucinateDebug = false;
constexpr F32 kTemporalSourceWeight = 0.01;
constexpr F32 kTemporalGamma = 1.0;
constexpr Bool kPerfectTemporal = true;
constexpr F32 kPdfForVeryRough = 1.0; // Something like 100 would have made more sense but it doesn't work well
#define TILE_SIZE 32

// The states of a tile
enum
{
	kClassNormal, // Always 1st
	kClassSky, // Always 2nd
	kClassMirror,
	kClassVeryRough,
};

// Functions
HVec4 encodeColorDepthAndSampleCount(HVec3 color, F16 depth, U32 sampleCount)
{
	HVec4 signs;
	[unroll] for(U32 i = 0; i < 4; i++)
	{
		signs[i] = (sampleCount & (1u << i)) ? 1.0 : -1.0;
	}

	return (HVec4(color, depth) + 0.01) * signs; // Add 0.01 to make sure that the sign sticks
}

void decodeColorDepthAndSampleCount(HVec4 rgba, out HVec3 color, out F16 depth, out U32 sampleCount)
{
	sampleCount = 0;
	[unroll] for(U32 i = 0; i < 4; ++i)
	{
		sampleCount |= (sign(rgba[i]) > 0.0) ? (1u << i) : 0u;
	}

	rgba = abs(rgba);
	rgba -= 0.01;

	color = rgba.xyz;
	depth = rgba.w;
}

template<typename T>
Bool isMirror(T roughness)
{
	return roughness <= T(kMinRoughness * 2);
}

// ===========================================================================
// Classification                                                            =
// ===========================================================================
#if NOT_ZERO(ANKI_TECHNIQUE_Classification)

SamplerState g_trilinearClampSampler : register(s0);

Texture2D<Vec4> g_gbufferRt1 : register(t0);
Texture2D<Vec4> g_depthTex : register(t1);

RWTexture2D<UVec4> g_classTimeMap : register(u0);
RWStructuredBuffer<DispatchIndirectArgs> g_indirectArgs : register(u1);

ANKI_FAST_CONSTANTS(ReflectionConstants, g_consts)

groupshared U32 g_minRoughness;
groupshared U32 g_maxRoughness;
groupshared U32 g_allSky;

[NumThreads(TILE_SIZE / 2, TILE_SIZE, 1)] void main(U32 svGroupIndex : SV_GroupIndex, UVec2 svDispatchThreadId : SV_DispatchThreadID,
													UVec2 svGroupId : SV_GroupID)
{
	if(svDispatchThreadId.x == 0 && svDispatchThreadId.y == 0)
	{
		// Reset the value for the next frame
		g_indirectArgs[0].m_threadGroupCountX = 0;
		g_indirectArgs[1].m_threadGroupCountX = 0;
	}

	if(svGroupIndex == 0)
	{
		g_minRoughness = asuint(1.0);
		g_maxRoughness = asuint(0.0);
		g_allSky = 0;
	}

	GroupMemoryBarrierWithGroupSync();

	UVec2 fullViewportSize;
	g_gbufferRt1.GetDimensions(fullViewportSize.x, fullViewportSize.y);

	const UVec2 realCoord = min(svDispatchThreadId, fullViewportSize / UVec2(2, 1) - 1u);
	const UVec2 logicalCoord = UVec2(realCoord.x * 2u + (realCoord.y & 1u), realCoord.y);

	const F32 depth = g_depthTex[logicalCoord].x;

	if(depth < 1.0)
	{
		const Vec4 rt1 = g_gbufferRt1[logicalCoord];
		const F32 roughness = unpackRoughnessFromGBuffer(rt1);

		U32 orig;
		InterlockedMax(g_maxRoughness, asuint(roughness), orig);
		InterlockedMin(g_minRoughness, asuint(roughness), orig);
	}
	else
	{
		InterlockedAdd(g_allSky, 1u);
	}

	GroupMemoryBarrierWithGroupSync();

	if(svGroupIndex == 0)
	{
		U32 tileClass = 0;
		if(g_allSky == TILE_SIZE / 2 * TILE_SIZE)
		{
			tileClass = kClassSky;
		}
		else if(asfloat(g_minRoughness) >= g_consts.m_roughnessCutoffToGiEdges.y && g_allSky == 0)
		{
			tileClass = kClassVeryRough;
		}
		else if(isMirror(asfloat(g_maxRoughness)) && g_allSky == 0)
		{
			tileClass = kClassMirror;
		}
		else
		{
			tileClass = kClassNormal;
		}

		g_classTimeMap[svGroupId] = tileClass;
	}
}
#endif

// ===========================================================================
// SSR                                                                       =
// ===========================================================================
#if NOT_ZERO(ANKI_TECHNIQUE_Ssr)
SamplerState g_trilinearClampSampler : register(s0);
SamplerComparisonState g_shadowSampler : register(s1);
SamplerState g_linearAnyRepeatSampler : register(s2);

Texture2D<Vec4> g_gbufferRt0 : register(t0);
Texture2D<Vec4> g_gbufferRt1 : register(t1);
Texture2D<Vec4> g_gbufferRt2 : register(t2);
Texture2D<Vec4> g_downscaledDepthTex : register(t3);
Texture2D<Vec4> g_depthTex : register(t4);
Texture2D<Vec4> g_lightBufferRt : register(t5);
StructuredBuffer<GlobalIlluminationProbe> g_giProbes : register(t6);
StructuredBuffer<Cluster> g_clusters : register(t7);
Texture2D<Vec4> g_shadowAtlasTex : register(t8);
Texture2D<UVec4> g_classTileMap : register(t9);

RWTexture2D<Vec4> g_colorAndPdfTex : register(u0);
RWTexture2D<Vec4> g_hitPosAndDepthTex : register(u1);
RWStructuredBuffer<PixelFailedSsr> g_pixelsFailedSsr : register(u2);
RWStructuredBuffer<DispatchIndirectArgs> g_indirectArgs : register(u3);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

ANKI_FAST_CONSTANTS(ReflectionConstants, g_consts)

#	define NUM_THREADS_SQRT 8

groupshared Vec4 g_viewHitPointAndSsrSuccess[NUM_THREADS_SQRT][NUM_THREADS_SQRT];
groupshared Vec4 g_colorAndDepth[NUM_THREADS_SQRT][NUM_THREADS_SQRT];

constexpr SampleClipmapFlag kSampleClipmapFlags =
	kSampleClipmapFlagBiasSamplePointTowardsCamera | kSampleClipmapFlagInvalidProbeRejection | kSampleClipmapFlagBackfacingProbeRejection;

Vec3 doLightShading(Vec3 worldPos, Vec3 viewPos, UVec2 coord, F32 depth)
{
	// Read
	GbufferInfo<F32> gbuffer = (GbufferInfo<F32>)0;
	unpackGBufferNoVelocity<F32>(g_gbufferRt0[coord], g_gbufferRt1[coord], g_gbufferRt2[coord], gbuffer);

	Vec3 outColor = gbuffer.m_emission;

#	if INDIRECT_DIFFUSE_CLIPMAPS
	const Vec3 irradiance =
		sampleClipmapIrradiance(worldPos, gbuffer.m_normal, g_globalRendererConstants.m_cameraPosition,
								g_globalRendererConstants.m_indirectDiffuseClipmaps, g_linearAnyRepeatSampler, kSampleClipmapFlags);
	outColor += irradiance * gbuffer.m_diffuse;
#	else
	// GI
	const Cluster cluster = getClusterFragCoord(g_clusters, g_globalRendererConstants, Vec3(coord.xy + 0.5, depth));
	outColor += sampleGiProbes<F32>(cluster, g_giProbes, gbuffer.m_normal, worldPos.xyz, g_trilinearClampSampler) * gbuffer.m_diffuse;
#	endif

	// Dir light
	const DirectionalLight dirLight = g_globalRendererConstants.m_directionalLight;
	if(dirLight.m_shadowCascadeCount_31bit_active_1bit & 1u)
	{
		const U32 shadowCascadeCount = dirLight.m_shadowCascadeCount_31bit_active_1bit >> 1u;
		F32 shadowFactor;
		if(shadowCascadeCount >> 1u)
		{
			const F32 negativeZViewSpace = -viewPos.z;

			const U32 cascadeIdx = computeShadowCascadeIndex(negativeZViewSpace, dirLight.m_shadowCascadeDistances, shadowCascadeCount);

			shadowFactor = computeShadowFactorDirLight<F32>(dirLight, cascadeIdx, worldPos, g_shadowAtlasTex, g_shadowSampler);
		}
		else
		{
			shadowFactor = 1.0;
		}

		const Vec3 l = -dirLight.m_direction;
		const F32 lambert = max(0.0, dot(l, gbuffer.m_normal));
		const Vec3 diffC = diffuseLobe(gbuffer.m_diffuse);
		outColor += diffC * dirLight.m_diffuseColor * lambert * shadowFactor;
	}

	return outColor;
}

struct SampleNormalFunc
{
	Vec3 sample(Vec2 uv)
	{
		const Vec3 gbufferNormal = unpackNormalFromGBuffer(g_gbufferRt2.SampleLevel(g_trilinearClampSampler, uv, 0.0));
		const Vec3 newNormal = mul(g_globalRendererConstants.m_matrices.m_view, Vec4(gbufferNormal, 0.0));
		return newNormal;
	}
};

// Calculations in view space
Bool doSsr(UVec2 logicalViewportSize, UVec2 realCoord, UVec2 logicalCoord, Vec2 uv, Vec3 viewPos, F32 depth, F32 randFactor, F32 roughness,
		   Vec3 viewReflDir, out Vec3 outColor, out Vec3 viewHitPoint)
{
	outColor = 0.0;
	viewHitPoint = 0.0;

	// Trace
	Vec2 hitUv;
	F32 hitDepth;
	{
		RayMarchingConfig config = (RayMarchingConfig)0;
		config.m_maxIterations = g_consts.m_ssrStepIncrement;
		config.m_depthTextureLod = 8.0; // Use the max LOD for ray marching
		config.m_stepIncrement = g_consts.m_ssrStepIncrement;

		const F32 minStepf = min(4u, config.m_stepIncrement);
		config.m_initialStepIncrement = U32(lerp(minStepf, config.m_stepIncrement, randFactor));

		if(kExtraSsrRejection)
		{
			config.m_backfaceRejection = true;
			config.m_minRayToBackgroundDistance = lerp(0.1f, 0.6f, roughness);
		}
		else
		{
			config.m_backfaceRejection = false;
			config.m_minRayToBackgroundDistance = kMaxF32;
		}

		SampleNormalFunc sampleNormalFunc;
		const Bool success =
			raymarchGroundTruth<SampleNormalFunc>(viewPos, viewReflDir, uv, depth, g_globalRendererConstants.m_matrices.m_projMat00_11_22_23,
												  g_globalRendererConstants.m_matrices.m_unprojectionParameters, g_downscaledDepthTex,
												  g_trilinearClampSampler, config, sampleNormalFunc, viewHitPoint, hitUv, hitDepth);

		if(!success)
		{
			return false;
		}
	}

	// Read the reflection
	if(!SSR_SAMPLE_GBUFFER)
	{
		// Reproject the hit point because you are reading the previous frame
		const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_reprojection, Vec4(uvToNdc(hitUv), hitDepth, 1.0));
		hitUv = ndcToUv(v4.xy / v4.w);

		// Read the light buffer
		const Vec3 ssrColor = g_lightBufferRt.SampleLevel(g_trilinearClampSampler, hitUv, 0.0).rgb;
		outColor = clamp(ssrColor, 0.0, kMaxF32); // Fix the value just in case
	}
	else
	{
		const Vec3 worldPos = mul(g_globalRendererConstants.m_matrices.m_cameraTransform, Vec4(viewHitPoint, 1.0));
		outColor = doLightShading(worldPos, viewHitPoint, hitUv * logicalViewportSize, hitDepth);
	}

	return true;
}

// Find if a neghbour is closer and we can use it
void bestCandidateToHallucinate(IVec2 svGroupThreadId, IVec2 offset, F32 depth, inout IVec2 neighbourOffset, inout F32 depthWeight,
								inout F32 candidateCount)
{
	const IVec2 svGroupThreadId2 = clamp(svGroupThreadId + offset, 0, NUM_THREADS_SQRT - 1);

	if(!g_viewHitPointAndSsrSuccess[svGroupThreadId2.x][svGroupThreadId2.y].w)
	{
		return;
	}

	candidateCount += 1.0;

	const F32 weight = calculateBilateralWeightDepth<F32>(depth, g_colorAndDepth[svGroupThreadId2.x][svGroupThreadId2.y].w, 1.0);
	if(weight > depthWeight)
	{
		depthWeight = weight;
		neighbourOffset = svGroupThreadId2 - svGroupThreadId;
	}
}

// All calculations in view space
[NumThreads(NUM_THREADS_SQRT, NUM_THREADS_SQRT, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID,
															  UVec2 svGroupThreadId : SV_GroupThreadID, U32 svGroupIndex : SV_GroupIndex)
{
	UVec2 halfViewportSize;
	g_hitPosAndDepthTex.GetDimensions(halfViewportSize.x, halfViewportSize.y);

	const UVec2 realCoord = min(svDispatchThreadId, halfViewportSize - 1u);
	const UVec2 logicalCoord = UVec2(realCoord.x * 2u + (realCoord.y & 1u), realCoord.y);
	const Vec2 uv = (Vec2(logicalCoord) + 0.5) / Vec2(halfViewportSize.x * 2u, halfViewportSize.y);

	// Sky
	const U32 tileClass = g_classTileMap[logicalCoord / TILE_SIZE];
	if(tileClass == kClassSky)
	{
		g_colorAndPdfTex[realCoord] = 0.0;
		g_hitPosAndDepthTex[realCoord] = 0.0;
		return;
	}

	const F32 depth = g_depthTex[logicalCoord].x;
	const Vec4 rt2 = g_gbufferRt2[logicalCoord];
	const Vec3 worldNormal = unpackNormalFromGBuffer(rt2);

	// Very rough
	if(tileClass == kClassVeryRough)
	{
		Vec4 worldPos = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjection, Vec4(uvToNdc(uv), depth, 1.0));
		worldPos.xyz /= worldPos.w;

		const Vec3 reflDir = reflect(normalize(worldPos.xyz - g_globalRendererConstants.m_cameraPosition), worldNormal);

#	if INDIRECT_DIFFUSE_CLIPMAPS
		const Vec3 col = sampleClipmapRadiance(worldPos, reflDir, g_globalRendererConstants.m_cameraPosition,
											   g_globalRendererConstants.m_indirectDiffuseClipmaps, g_linearAnyRepeatSampler, kSampleClipmapFlags);
#	else
		Cluster cluster = getClusterFragCoord(g_clusters, g_globalRendererConstants, Vec3(logicalCoord.xy + 0.5, depth));
		const Vec3 col = sampleGiProbes<F32>(cluster, g_giProbes, reflDir, worldPos.xyz, g_trilinearClampSampler);
#	endif

		Vec3 worldHitPos = worldPos + reflDir * 1.0;
		worldHitPos -= g_globalRendererConstants.m_cameraPosition;
		g_hitPosAndDepthTex[realCoord] = Vec4(worldHitPos, 1.0 - depth);
		g_colorAndPdfTex[realCoord] = Vec4(col, kPdfForVeryRough);

		return;
	}

	// Read stuff
	const Vec4 rt1 = g_gbufferRt1[logicalCoord];
	const Vec3 viewNormal = mul(g_globalRendererConstants.m_matrices.m_view, Vec4(worldNormal, 0.0));
	const F32 roughness = unpackRoughnessFromGBuffer(rt1);

	const Vec2 ndc = uvToNdc(uv);
	const Vec3 viewPos = cheapPerspectiveUnprojection(g_globalRendererConstants.m_matrices.m_unprojectionParameters, ndc, depth);

	// Rand
	const UVec3 seed = rand3DPCG16(UVec3(logicalCoord, g_globalRendererConstants.m_frame % 8u));
	const Vec2 randFactors = hammersleyRandom16(g_globalRendererConstants.m_frame % 64u, 64u, seed);

	// Compute refl vector
	const Vec3 viewDir = -normalize(viewPos);

	// Sample GI probes factor
	const F32 sampleGiProbesLerp = smoothstep(g_consts.m_roughnessCutoffToGiEdges.x, g_consts.m_roughnessCutoffToGiEdges.y, roughness);
	const Bool bSampleGiProbes = tileClass == kClassNormal && (sampleGiProbesLerp > randFactors.x); // Choose stocasticly

	// Sample probes or do SS trace
	Vec3 outColor;
	Vec3 viewReflDir;
	Vec3 viewHitPoint;
	F32 pdf;
	Bool ssrSuccess;
	if(bSampleGiProbes)
	{
		viewReflDir = reflect(-viewDir, viewNormal);

		Cluster cluster = getClusterFragCoord(g_clusters, g_globalRendererConstants, Vec3(logicalCoord.xy + 0.5, depth));

		const Vec3 woldReflDir = mul(g_globalRendererConstants.m_matrices.m_cameraTransform, Vec4(viewReflDir, 0.0));

		Vec4 worldPos = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjection, Vec4(uvToNdc(uv), depth, 1.0));
		worldPos.xyz /= worldPos.w;

#	if INDIRECT_DIFFUSE_CLIPMAPS
		outColor = sampleClipmapRadiance(worldPos, woldReflDir, g_globalRendererConstants.m_cameraPosition,
										 g_globalRendererConstants.m_indirectDiffuseClipmaps, g_linearAnyRepeatSampler, kSampleClipmapFlags);
#	else
		outColor = sampleGiProbes<F32>(cluster, g_giProbes, woldReflDir, worldPos.xyz, g_trilinearClampSampler);
#	endif

		viewHitPoint = viewPos + viewReflDir * 1.0;
		pdf = kPdfForVeryRough;
		ssrSuccess = true;
	}
	else
	{
		// SS trace
		if(!kStochasticReflections || tileClass == kClassMirror)
		{
			viewReflDir = reflect(-viewDir, viewNormal);
			pdf = pdfVndfIsotropic(viewReflDir, viewDir, kMinRoughness, viewNormal);
		}
		else
		{
			viewReflDir = sampleReflectionVectorIsotropic(viewDir, viewNormal, roughness, randFactors, 4, pdf);
		}

		ssrSuccess = doSsr(halfViewportSize * UVec2(2, 1), realCoord, logicalCoord, uv, viewPos, depth, randFactors.x, roughness, viewReflDir,
						   outColor, viewHitPoint);
	}

	// Stash to groupshared
	if(kSsrHallucinate)
	{
		g_viewHitPointAndSsrSuccess[svGroupThreadId.x][svGroupThreadId.y] = Vec4(viewHitPoint, ssrSuccess);
		g_colorAndDepth[svGroupThreadId.x][svGroupThreadId.y] = Vec4(outColor, depth);
		GroupMemoryBarrierWithGroupSync();
	}

	if(depth == 1.0)
	{
		// Sky
		g_colorAndPdfTex[realCoord] = 0.0;
		g_hitPosAndDepthTex[realCoord] = 0.0;
		return;
	}

	// Hallucinate if needed
	if(!ssrSuccess && kSsrHallucinate)
	{
		IVec2 neighbourOffset = -100;
		F32 depthWeight = 0.0;
		F32 candidateCount = 0.0;

		bestCandidateToHallucinate(svGroupThreadId, IVec2(0, -1), depth, neighbourOffset, depthWeight, candidateCount);
		bestCandidateToHallucinate(svGroupThreadId, IVec2(0, 1), depth, neighbourOffset, depthWeight, candidateCount);
		bestCandidateToHallucinate(svGroupThreadId, IVec2(1, -1), depth, neighbourOffset, depthWeight, candidateCount);
		bestCandidateToHallucinate(svGroupThreadId, IVec2(1, 1), depth, neighbourOffset, depthWeight, candidateCount);

		if(neighbourOffset.x != -100 && candidateCount == 4.0)
		{
			// Found something

			const UVec2 neighbourSvGroupThreadId = svGroupThreadId + neighbourOffset;

			viewHitPoint = g_viewHitPointAndSsrSuccess[neighbourSvGroupThreadId.x][neighbourSvGroupThreadId.y].xyz;

			viewReflDir = normalize(viewHitPoint - viewPos);
			const Vec3 viewDir = normalize(-viewPos);
			const F32 alpha = square(roughness);
			pdf = pdfVndfIsotropic(viewReflDir, viewDir, alpha, viewNormal);

			ssrSuccess = g_viewHitPointAndSsrSuccess[neighbourSvGroupThreadId.x][neighbourSvGroupThreadId.y].w;

			outColor = g_colorAndDepth[neighbourSvGroupThreadId.x][neighbourSvGroupThreadId.y].xyz;

			if(kSsrHallucinateDebug)
			{
				outColor *= Vec3(0.0, 10.0, 0.0);
			}
		}
	}

	// Complete
	if(ssrSuccess)
	{
		// Write to the image

		g_colorAndPdfTex[realCoord] = Vec4(outColor, pdf);

		Vec3 worldHitPos = mul(g_globalRendererConstants.m_matrices.m_cameraTransform, Vec4(viewHitPoint, 1.0));
		worldHitPos -= g_globalRendererConstants.m_cameraPosition; // Move it with camera to avoid precision issues since it's stored in fp16

		// Store depth in reverse for better precision
		g_hitPosAndDepthTex[realCoord] = Vec4(worldHitPos, 1.0 - depth);
	}
	else
	{
		if(kDebugSsr)
		{
			g_colorAndPdfTex[realCoord] = Vec4(1.0, 0.0, 1.0, 0.0);
			g_hitPosAndDepthTex[realCoord] = Vec4(1.0, 0.0, 1.0, 0.0);
			return;
		}

		U32 writeOffset;
		InterlockedAdd(g_indirectArgs[0].m_threadGroupCountX, 1u, writeOffset);

		const Vec3 reflDirWorld = mul(g_globalRendererConstants.m_matrices.m_cameraTransform, Vec4(viewReflDir, 0.0)).xyz;

		PixelFailedSsr failedPixel;
		failedPixel.m_pixel = (realCoord.x << 16u) | realCoord.y;
		failedPixel.m_reflectionDirAndRoughness = packSnorm4x8(Vec4(reflDirWorld, roughness));
		failedPixel.m_pdf_f16_rayDirT_f16 = f32tof16(pdf) << 16u;
		failedPixel.m_pdf_f16_rayDirT_f16 |= f32tof16(length(viewPos - viewHitPoint));

		SBUFF(g_pixelsFailedSsr, writeOffset) = failedPixel;

		// Set the threadgroup count for Z for ReflectionProbeFallback
		const U32 failedCount = writeOffset + 1;
		InterlockedMax(g_indirectArgs[1].m_threadGroupCountX, (failedCount + (64 - 1)) / 64);
	}
}
#endif

// ===========================================================================
// ReflectionProbeFallback                                                   =
// ===========================================================================
#if NOT_ZERO(ANKI_TECHNIQUE_ReflectionProbeFallback)

Texture2D<Vec4> g_depthTex : register(t0);
StructuredBuffer<PixelFailedSsr> g_pixelsFailedSsr : register(t1);
StructuredBuffer<ReflectionProbe> g_reflectionProbes : register(t2);
StructuredBuffer<Cluster> g_clusters : register(t3);
StructuredBuffer<U32> g_pixelsFailedSsrCount : register(t4);
Texture2D<Vec4> g_envMap : register(t5);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

SamplerState g_trilinearClampSampler : register(s0);

RWTexture2D<Vec4> g_colorAndPdfTex : register(u0);
RWTexture2D<Vec4> g_hitPosAndDepthTex : register(u1);

[NumThreads(64, 1, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID)
{
	if(svDispatchThreadId.x >= g_pixelsFailedSsrCount[0])
	{
		return;
	}

	UVec2 viewportSize;
	g_depthTex.GetDimensions(viewportSize.x, viewportSize.y);

	const PixelFailedSsr pixelFailedSsr = g_pixelsFailedSsr[svDispatchThreadId.x];
	const UVec2 realCoord = UVec2(pixelFailedSsr.m_pixel >> 16u, pixelFailedSsr.m_pixel & 0xFFFFu);
	const UVec2 logicalCoord = UVec2(realCoord.x * 2u + (realCoord.y & 1u), realCoord.y);
	const Vec4 packed = unpackSnorm4x8<F32>(pixelFailedSsr.m_reflectionDirAndRoughness);
	const Vec3 reflDir = packed.xyz;
	const F32 roughness = packed.w;
	const F32 pdf = f16tof32(pixelFailedSsr.m_pdf_f16_rayDirT_f16 >> 16u);

	const F32 depth = g_depthTex[logicalCoord].x;
	const Vec2 ndc = uvToNdc((Vec2(logicalCoord) + 0.5) / Vec2(viewportSize));
	const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjectionJitter, Vec4(ndc, depth, 1.0));
	const Vec3 worldPos = v4.xyz / v4.w;

	Cluster cluster = getClusterFragCoord(g_clusters, g_globalRendererConstants, Vec3(logicalCoord.xy + 0.5, depth));

	const F32 reflLod = (g_globalRendererConstants.m_reflectionProbesMipCount - 1.0f) * roughness;
	Vec3 probeColor = sampleReflectionProbes<F32>(cluster, g_reflectionProbes, reflDir, worldPos, reflLod, g_trilinearClampSampler);

	if(probeColor.x < 0.0)
	{
		// No probe, sample sky
		if(g_globalRendererConstants.m_sky.m_type == 0)
		{
			probeColor = g_globalRendererConstants.m_sky.m_solidColor;
		}
		else
		{
			const Vec2 uv = (g_globalRendererConstants.m_sky.m_type == 1) ? equirectangularMapping(reflDir) : octahedronEncode(reflDir);
			probeColor = g_envMap.SampleLevel(g_trilinearClampSampler, uv, 0.0).xyz;
		}
	}

	// Write out
	g_colorAndPdfTex[realCoord] = Vec4(probeColor, max(0.0, pdf));

	// Move it with camera to avoid precision issues since it's stored in fp16
	// Store depth in reverse for better precision
	const Vec3 hitPos = worldPos + reflDir * 1.0;
	g_hitPosAndDepthTex[realCoord] = Vec4(hitPos - g_globalRendererConstants.m_cameraPosition, 1.0 - depth);
}
#endif

// ===========================================================================
// RayGen                                                                    =
// ===========================================================================
#if ANKI_RAY_GEN_SHADER

struct Consts
{
	F32 m_maxRayT;
	U32 m_giProbeCount;
	F32 m_padding1;
	F32 m_padding2;
};
ANKI_FAST_CONSTANTS(Consts, g_consts)

template<typename T>
vector<T, 3> getDiffuseIndirect(Vec3 worldPos, Vec3 worldNormal)
{
	const U32 probeCount = getStructuredBufferElementCount(g_giProbes);
	U32 i;
	for(i = 0; i < probeCount; ++i)
	{
		if(any(worldPos >= g_giProbes[i].m_aabbMax) || any(worldPos <= g_giProbes[i].m_aabbMin))
		{
			continue;
		}
		else
		{
			break;
		}
	}

	const Bool probeFound = (i != probeCount);
	if(probeFound)
	{
		const GpuSceneGlobalIlluminationProbe probe = g_giProbes[i];
		return sampleGlobalIllumination<T>(worldPos, worldNormal, probe, getBindlessTexture3DVec4(probe.m_volumeTexture), g_linearAnyClampSampler);
	}
	else
	{
		return T(0);
	}
}

[shader("raygeneration")] void main()
{
	UVec2 halfViewportSize;
	g_hitPosAndDepthTex.GetDimensions(halfViewportSize.x, halfViewportSize.y);

	const PixelFailedSsr pixelFailedSsr = g_pixelsFailedSsr[DispatchRaysIndex().x];
	const UVec2 realCoord = UVec2(pixelFailedSsr.m_pixel >> 16u, pixelFailedSsr.m_pixel & 0xFFFFu);
	const UVec2 logicalCoord = UVec2(realCoord.x * 2u + (realCoord.y & 1u), realCoord.y);
	const Vec4 packed = unpackSnorm4x8<F32>(pixelFailedSsr.m_reflectionDirAndRoughness);
	const Vec3 reflDir = packed.xyz;
	const F32 roughness = packed.w;
	const F32 pdf = f16tof32(pixelFailedSsr.m_pdf_f16_rayDirT_f16 >> 16u);
	const F32 tmin = f16tof32(pixelFailedSsr.m_pdf_f16_rayDirT_f16 & 0xFFFFu);

	const F32 depth = g_depthTex[logicalCoord].x;
	const Vec2 ndc = uvToNdc((Vec2(logicalCoord) + 0.5) / Vec2(halfViewportSize.x * 2u, halfViewportSize.y));
	const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjectionJitter, Vec4(ndc, depth, 1.0));
	const Vec3 worldPos = v4.xyz / v4.w;

	const DirectionalLight dirLight = g_globalRendererConstants.m_directionalLight;

	// The more rough and the more far this pixel is then instruct the hit shaders to choose less detail mip
	const F32 distanceToMaxMip = 50.0;
	const F32 pixelDistFromCamera = length(worldPos - g_globalRendererConstants.m_cameraPosition);
	const F32 distFactor = pow(pixelDistFromCamera / distanceToMaxMip, 4.0);
	const F32 maxMips = 8.0;
	const F16 textureLod = max(roughness, distFactor) * maxMips;

	// Trace
	GBufferLight<F16> gbuffer;
	F32 rayT;
	Bool unused;
	const Bool hasHitSky = !materialRayTrace(worldPos, reflDir, max(tmin + kTMinBias, 0.05), g_consts.m_maxRayT, textureLod, gbuffer, rayT, unused);

	const Vec3 hitPos = worldPos + reflDir * rayT;

	// Do simple light shading
	HVec3 radiance = directLighting(gbuffer, hitPos, hasHitSky, kTryShadowmapFirst, g_consts.m_maxRayT);

	if(!hasHitSky)
	{
#	if INDIRECT_DIFFUSE_CLIPMAPS
		const SampleClipmapFlag flags =
			kSampleClipmapFlagFullQuality & ~(kSampleClipmapFlagChebyshevOcclusion | kSampleClipmapFlagAccurateClipmapSelection);
		const HVec3 irradiance = sampleClipmapIrradiance(hitPos, gbuffer.m_worldNormal, g_globalRendererConstants.m_cameraPosition,
														 g_globalRendererConstants.m_indirectDiffuseClipmaps, g_linearAnyRepeatSampler, flags);
		radiance += gbuffer.m_diffuse * irradiance;
#	else
		if(g_consts.m_giProbeCount > 0)
		{
			const HVec3 indirectDiffuse = getDiffuseIndirect<F16>(hitPos, gbuffer.m_worldNormal);
			radiance += gbuffer.m_diffuse * indirectDiffuse;
		}
#	endif
	}

	g_colorAndPdfTex[realCoord] = Vec4(radiance, max(0.0, pdf));

	// Move it with camera to avoid precision issues since it's stored in fp16
	// Store depth in reverse for better precision
	g_hitPosAndDepthTex[realCoord] = Vec4(hitPos - g_globalRendererConstants.m_cameraPosition, 1.0 - depth);
}
#endif // ANKI_RAY_GEN_SHADER

// ===========================================================================
// SpatialDenoise                                                            =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_SpatialDenoise)
Texture2D<Vec4> g_colorAndPdfTex : register(t0);
Texture2D<Vec4> g_hitPosAndDepthTex : register(t1);
Texture2D<Vec4> g_depthTex : register(t2);
Texture2D<Vec4> g_gbufferRt1 : register(t3);
Texture2D<Vec4> g_gbufferRt2 : register(t4);
Texture2D<UVec4> g_classTileMap : register(t5);

RWTexture2D<Vec4> g_denoisedTex : register(u0);
RWTexture2D<Vec4> g_hitPosTex : register(u1);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

ANKI_FAST_CONSTANTS(ReflectionConstants, g_consts)

groupshared Vec4 g_colorAndPdf[8][8];
groupshared Vec4 g_hitPosAndDepth[8][8];

// Return true if the coord contains a pixel that was populated by the previous passes
Bool isCheckerboardWhite(UVec2 coord)
{
	return (coord.y & 1u) == (coord.x & 1u);
}

void reconstructCheckerboardBlack(IVec2 svGroupThreadId, F32 refDepth, inout Vec3 color, inout F32 pdf, inout Vec3 hitPos, inout F32 sumWeight)
{
	if(any(svGroupThreadId < 0u) || any(svGroupThreadId > 7u))
	{
		return;
	}

	const F32 weight = calculateBilateralWeightDepth<F32>(refDepth, g_hitPosAndDepth[svGroupThreadId.x][svGroupThreadId.y].w, 1.0);

	color += g_colorAndPdf[svGroupThreadId.x][svGroupThreadId.y].xyz * weight;
	pdf += g_colorAndPdf[svGroupThreadId.x][svGroupThreadId.y].w * weight;
	hitPos += g_hitPosAndDepth[svGroupThreadId.x][svGroupThreadId.y].xyz * weight;

	sumWeight += weight;
}

[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID, UVec2 svGroupThreadId : SV_GROUPTHREADID,
								U32 svGroupIndex : SV_GROUPINDEX)
{
	UVec2 viewportSize;
	g_colorAndPdfTex.GetDimensions(viewportSize.x, viewportSize.y);
	const UVec2 halfViewportSize = UVec2(viewportSize.x / 2u, viewportSize.y);

	const UVec2 coord = min(svDispatchThreadId, viewportSize - 1u);
	const UVec2 checkerboardCoord = UVec2(coord.x / 2u, coord.y);

	const F32 refDepth = g_depthTex[coord];

	Vec3 refColor = 0.0;
	F32 refPdf = 0.0;
	Vec3 refHitPos = 0.0;
	if(isCheckerboardWhite(coord))
	{
		// Dump pixel data to shared memory to be used to reconstruct other pixels
		const Vec4 rgba = g_colorAndPdfTex[checkerboardCoord];
		refColor = rgba.xyz;
		refPdf = rgba.w;
		g_colorAndPdf[svGroupThreadId.x][svGroupThreadId.y] = rgba;

		refHitPos = g_hitPosAndDepthTex[checkerboardCoord].xyz;
		g_hitPosAndDepth[svGroupThreadId.x][svGroupThreadId.y] = Vec4(refHitPos, refDepth);
	}
	else
	{
		g_colorAndPdf[svGroupThreadId.x][svGroupThreadId.y] = 0.0;
		g_hitPosAndDepth[svGroupThreadId.x][svGroupThreadId.y] = Vec4(0.0, 0.0, 0.0, refDepth);
	}

	GroupMemoryBarrierWithGroupSync();

	if(!isCheckerboardWhite(coord))
	{
		// Reconstruct missing pixel
		const IVec2 svGroupThreadIdi = svGroupThreadId;

		F32 sumWeight = 0.001;
		reconstructCheckerboardBlack(svGroupThreadIdi + IVec2(-1, 0), refDepth, refColor, refPdf, refHitPos, sumWeight);
		reconstructCheckerboardBlack(svGroupThreadIdi + IVec2(+1, 0), refDepth, refColor, refPdf, refHitPos, sumWeight);
		reconstructCheckerboardBlack(svGroupThreadIdi + IVec2(0, +1), refDepth, refColor, refPdf, refHitPos, sumWeight);
		reconstructCheckerboardBlack(svGroupThreadIdi + IVec2(0, -1), refDepth, refColor, refPdf, refHitPos, sumWeight);

		refColor /= sumWeight;
		refPdf /= sumWeight;
		refHitPos /= sumWeight;
	}

	// NOTE: We are done with groupshared so we can use "return"

	const U16 tileClass = g_classTileMap[coord / TILE_SIZE];

	if(tileClass == kClassSky || refDepth == 1.0)
	{
		g_denoisedTex[coord] = 0.0;
		g_hitPosTex[coord] = 0.0;
		return;
	}

	const Vec4 rt1 = g_gbufferRt1[coord];
	const F32 roughness = unpackRoughnessFromGBuffer(rt1);
	const F32 alpha = square(roughness);

	if(kDisableDenoising || tileClass == kClassVeryRough || tileClass == kClassMirror || roughness >= g_consts.m_roughnessCutoffToGiEdges.y
	   || isMirror(roughness))
	{
		g_denoisedTex[coord] = Vec4(refColor, 1.0 - refDepth); // Store depth in reverse for better precision
		g_hitPosTex[coord] = Vec4(refHitPos - g_globalRendererConstants.m_cameraPosition, 0.0);
		return;
	}

	const Vec2 ndc = uvToNdc((Vec2(coord) + 0.5) / Vec2(viewportSize));
	const Vec4 v4 = mul(g_globalRendererConstants.m_matrices.m_invertedViewProjectionJitter, Vec4(ndc, refDepth, 1.0));
	const Vec3 worldPos = v4.xyz / v4.w;

	const Vec3 viewDir = normalize(g_globalRendererConstants.m_cameraPosition - worldPos);

	Vec3 newHitPos = 0.0;

	const Vec4 rt2 = g_gbufferRt2[coord];
	const Vec3 worldNormal = unpackNormalFromGBuffer(rt2);

	const UVec3 seed = rand3DPCG16(UVec3(coord, g_globalRendererConstants.m_frame % 8u));
	const Vec2 randFactors = hammersleyRandom16(g_globalRendererConstants.m_frame % 64u, 64u, seed);

	const F32 sinTheta = sin(randFactors.x * 2.0 * kPi);
	const F32 cosTheta = cos(randFactors.x * 2.0 * kPi);

	const F32 sampleCount = ARRAY_SIZE(SPATIAL_UPSCALING_POISON_KERNEL) + 1.0;
	F32 avgLuma = computeLuminance(refColor) / sampleCount;
	Vec3 outColor = refColor;
	F32 weightSum = refPdf;
	for(U32 i = 0u; i < ARRAY_SIZE(SPATIAL_UPSCALING_POISON_KERNEL); ++i)
	{
		const Vec2 diskPoint = SPATIAL_UPSCALING_POISON_KERNEL[i];

		// Rotate the disk point
		Vec2 rotatedDiskPoint;
		rotatedDiskPoint.x = diskPoint.x * cosTheta - diskPoint.y * sinTheta;
		rotatedDiskPoint.y = diskPoint.y * cosTheta + diskPoint.x * sinTheta;

		rotatedDiskPoint.x /= 2.0; // Adjust because the input textures are in half width

		// Offset calculation
		const IVec2 newCoord = clamp(IVec2(checkerboardCoord) + rotatedDiskPoint * kSpatialUpscalingPcfTexelOffset, 0, halfViewportSize - 1u);

		const Vec4 rgba = g_hitPosAndDepthTex[newCoord];
		const F32 sampleDepth = 1.0 - rgba.w;
		const Vec3 hitPos = rgba.xyz + g_globalRendererConstants.m_cameraPosition;

		const Vec3 reflectedDir = normalize(hitPos - worldPos);
		const F32 pdf = pdfVndfIsotropic(reflectedDir, viewDir, alpha, worldNormal);

		const F32 weight = pdf * calculateBilateralWeightDepth<F32>(refDepth, sampleDepth, 1.0);

		if(weight > 0.001)
		{
			const Vec3 sampleColor = g_colorAndPdfTex[newCoord].xyz;

			outColor += sampleColor * weight;
			weightSum += weight;
			avgLuma += computeLuminance(sampleColor) / sampleCount;

			newHitPos += hitPos * weight;
		}
	}

	if(weightSum > 0.001)
	{
		outColor /= weightSum;
		newHitPos /= weightSum;
	}
	else
	{
		outColor = 0.0;
		newHitPos = g_globalRendererConstants.m_cameraPosition;
	}

	// Remove fireflies
	const F32 luma = computeLuminance(outColor);
	if(luma > avgLuma && luma > 0.001)
	{
		outColor *= avgLuma / luma;
	}

	g_denoisedTex[coord] = Vec4(outColor, 1.0 - refDepth); // Store depth in reverse for better precision
	g_hitPosTex[coord] = Vec4(newHitPos - g_globalRendererConstants.m_cameraPosition, 0.0);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_SpatialDenoise

// ===========================================================================
// TemporalDenoise                                                           =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_TemporalDenoise)
SamplerState g_linearAnyClampSampler : register(s0);

Texture2D<Vec4> g_colorAndDepth : register(t0);
Texture2D<Vec4> g_historyTex : register(t1);
Texture2D<Vec4> g_momentsHistoryTex : register(t2);
Texture2D<Vec4> g_motionVectorsTex : register(t3);
Texture2D<Vec4> g_hitPosTex : register(t4);
Texture2D<UVec4> g_classTileMap : register(t5);

RWTexture2D<Vec4> g_outTex : register(u0);
RWTexture2D<Vec4> g_momentsTex : register(u1);

ConstantBuffer<GlobalRendererConstants> g_globalRendererConstants : register(b0);

// Spacial history UV calculation to decrease parallax reprojection effect
Vec2 computeHistoryUv(UVec2 coords, Vec2 uv)
{
	// Compute the history UV by reprojecting the hit point
	const Vec3 hitWorldPos = g_hitPosTex[coords].xyz + g_globalRendererConstants.m_cameraPosition;

	Vec4 clipPos = mul(g_globalRendererConstants.m_matrices.m_viewProjection, Vec4(hitWorldPos, 1.0));
	clipPos.xy /= clipPos.w;

	Vec4 prevClipPos = mul(g_globalRendererConstants.m_previousMatrices.m_viewProjection, Vec4(hitWorldPos, 1.0));
	prevClipPos.xy /= prevClipPos.w;

	const Vec2 diff = ndcToUv(prevClipPos.xy) - ndcToUv(clipPos.xy);
	const Vec2 hitHistoryUv = uv + diff;

	// Read the motion vectors as well
	const Vec2 motionHistoryUv = uv + g_motionVectorsTex.SampleLevel(g_linearAnyClampSampler, uv, 0.0f).xy;

	// Blend the 2 histories. The more the projected hit point is in the view the more we use it
	F32 factor = max(abs(clipPos.x), abs(clipPos.y));
	factor = min(factor, 1.0);
	factor = pow(factor, 8.0);
	factor = 1 - factor;

	const Vec2 historyUv = lerp(motionHistoryUv, hitHistoryUv, factor);

	return historyUv;
}

[numthreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DISPATCHTHREADID)
{
	UVec2 textureSize;
	g_colorAndDepth.GetDimensions(textureSize.x, textureSize.y);

	const UVec2 coord = min(svDispatchThreadId, textureSize - 1);
	const Vec2 uv = (Vec2(coord) + 0.5f) / textureSize;

	const U16 tileClass = g_classTileMap[coord / TILE_SIZE];

	if(kDisableDenoising || tileClass != kClassNormal)
	{
		g_outTex[coord] = g_colorAndDepth[coord];
		g_momentsTex[coord] = 0.0;
		return;
	}

	// Read history
	const Vec2 historyUv = computeHistoryUv(coord, uv);
	Vec3 history = g_historyTex.SampleLevel(g_linearAnyClampSampler, historyUv, 0.0f);

	// TAA
	const Vec3 finalVal = computeTemporalAA<F32>(g_colorAndDepth, g_linearAnyClampSampler, history, coord);

	// Temporal variance
	const Vec2 momentsHistory = g_momentsHistoryTex.SampleLevel(g_linearAnyClampSampler, historyUv, 0.0f).xy;
	Vec2 crntMoments;
	crntMoments.x = computeLuminance(finalVal);
	crntMoments.y = crntMoments.x * crntMoments.x;
	const Vec2 moments = lerp(crntMoments, momentsHistory, 0.25);

	// Write value
	const F32 depth = g_colorAndDepth[coord].w;
	g_outTex[coord] = Vec4(finalVal, depth);
	g_momentsTex[coord] = Vec4(moments, 0.0, 0.0);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_TemporalDenoise

// ===========================================================================
// BilateralDenoiseHorizontal                                                =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_BilateralDenoiseHorizontal)
Texture2D<Vec4> g_colorAndDepth : register(t0);
Texture2D<Vec4> g_momentsTex : register(t1);
Texture2D<Vec4> g_gbufferRt1 : register(t2);
Texture2D<UVec4> g_classTileMap : register(t3);

RWTexture2D<Vec4> g_outTex : register(u0);

ANKI_FAST_CONSTANTS(ReflectionConstants, g_consts)

F16 computeVarianceCenter(IVec2 coord, UVec2 textureSize)
{
#	if 1
	const F16 kernel[2][2] = {{1.0 / 4.0, 1.0 / 8.0}, {1.0 / 8.0, 1.0 / 16.0}};
	const I32 radius = 1;

	HVec2 sumMoments = 0.0f;
	for(I32 yy = -radius; yy <= radius; yy++)
	{
		for(I32 xx = -radius; xx <= radius; xx++)
		{
			IVec2 newCoord = coord + IVec2(xx, yy);
			newCoord = clamp(newCoord, 0, textureSize - 1);

			const F16 k = kernel[abs(xx)][abs(yy)];
			sumMoments += g_momentsTex[newCoord].xy * k;
		}
	}

	return abs(sumMoments.y - sumMoments.x * sumMoments.x);
#	else
	Vec2 sumMoments = g_momentsTex[coord].xy;
	return abs(sumMoments.y - sumMoments.x * sumMoments.x);
#	endif
}

[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID)
{
	UVec2 outSize;
	g_outTex.GetDimensions(outSize.x, outSize.y);

	const UVec2 coord = min(svDispatchThreadId, outSize - 1);
	HVec4 rgba = g_colorAndDepth[coord];
	const F16 refDepth = rgba.w;
	const HVec3 centerColor = rgba.xyz;

	const U16 tileClass = g_classTileMap[coord / TILE_SIZE];

	if(kDisableDenoising || tileClass != kClassNormal)
	{
		g_outTex[coord] = encodeColorDepthAndSampleCount(centerColor, refDepth, 0u);
		return;
	}

	const HVec4 rt1 = g_gbufferRt1[coord];
	const F16 roughness = unpackRoughnessFromGBuffer<F16>(rt1, 0.0);
	const F16 sqRoughness = sqrt(roughness);

	if(roughness >= g_consts.m_roughnessCutoffToGiEdges.y)
	{
		g_outTex[coord] = encodeColorDepthAndSampleCount(centerColor, refDepth, 0u);
		return;
	}

	const F16 variance = sqrt(computeVarianceCenter(coord, outSize)) * 100.0;

	const F16 lerpFactor = sqRoughness * min(1.0, max(sqRoughness, variance));

	const F16 sampleCount = round(lerp(0, kMaxBilateralSamples, lerpFactor));

	F16 weightSum = gaussianWeight2d<F16>(kGaussianSigma, 0.0, 0.0);
	HVec3 colorSum = centerColor * weightSum;
	for(F16 x = -sampleCount; x <= sampleCount; x += 1.0)
	{
		if(x == 0.0)
		{
			continue;
		}

		IVec2 newCoord = coord + IVec2(x, 0);
		newCoord.x = clamp(newCoord.x, 0, outSize.x - 1);

		rgba = g_colorAndDepth[newCoord];
		const F16 sampleDepth = rgba.w;
		const HVec3 sampleColor = rgba.xyz;

		const F16 gWeight = gaussianWeight<F16>(kGaussianSigma, x / sampleCount);
		const F16 depthWeight = calculateBilateralWeightDepth<F16>(refDepth, sampleDepth, 1.0);
		const F16 weight = gWeight * depthWeight;

		colorSum += sampleColor * weight;
		weightSum += weight;
	}

	colorSum /= weightSum;

	g_outTex[coord] = encodeColorDepthAndSampleCount(colorSum, refDepth, sampleCount);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_BilateralDenoiseHorizontal

// ===========================================================================
// BilateralDenoiseVertical                                                  =
// ===========================================================================
#if ANKI_COMPUTE_SHADER && NOT_ZERO(ANKI_TECHNIQUE_BilateralDenoiseVertical)
Texture2D<Vec4> g_colorAndDepthAndSampleCount : register(t0);
Texture2D<UVec4> g_classTileMap : register(t1);

RWTexture2D<Vec4> g_outTex : register(u0);

[NumThreads(8, 8, 1)] void main(UVec2 svDispatchThreadId : SV_DispatchThreadID)
{
	UVec2 outSize;
	g_outTex.GetDimensions(outSize.x, outSize.y);

	const UVec2 coord = min(svDispatchThreadId, outSize - 1);

	U32 sampleCountu;
	F16 refDepth;
	HVec3 refColor;
	decodeColorDepthAndSampleCount(g_colorAndDepthAndSampleCount[coord], refColor, refDepth, sampleCountu);
	const F16 sampleCount = sampleCountu;

	const U16 tileClass = g_classTileMap[coord / TILE_SIZE];

	if(kDisableDenoising || tileClass >= kClassSky)
	{
		g_outTex[coord] = HVec4(refColor, 1.0);
		return;
	}

	F16 weightSum = gaussianWeight<F16>(kGaussianSigma, 0.0);
	HVec3 colorSum = refColor * weightSum;
	for(F16 y = -sampleCount; y <= sampleCount; y += 1.0)
	{
		if(y == 0.0)
		{
			continue;
		}

		IVec2 newCoord = coord + IVec2(0.0, y);
		newCoord.y = clamp(newCoord.y, 0, outSize.y - 1);

		F16 sampleDepth;
		HVec3 sampleColor;
		U32 unused;
		decodeColorDepthAndSampleCount(g_colorAndDepthAndSampleCount[newCoord], sampleColor, sampleDepth, unused);

		const F16 gWeight = gaussianWeight<F16>(kGaussianSigma, y / sampleCount);
		const F16 depthWeight = calculateBilateralWeightDepth<F16>(refDepth, sampleDepth, 1.0);
		const F16 weight = gWeight * depthWeight;

		colorSum += sampleColor * weight;
		weightSum += weight;
	}

	colorSum /= weightSum;

	g_outTex[coord] = HVec4(colorSum, 1.0);
}
#endif // ANKI_COMPUTE_SHADER && ANKI_TECHNIQUE_BilateralDenoiseVertical
